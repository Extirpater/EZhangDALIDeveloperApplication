{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a65b55",
   "metadata": {},
   "source": [
    "# GNN Training and Label Propogation\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### Still WIP\n",
    "\n",
    "1. Generate Graph Dataset \n",
    "2. Label Propogation\n",
    "3. Train GNN\n",
    "4. GNN ROC\n",
    "\n",
    "By: Edward Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd9e5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\nimport pickle\\ndf = pd.read_pickle('DataSplit.pkl')\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "import pickle\n",
    "df = pd.read_pickle('DataSplit.pkl')\n",
    "for basename in df.ID.unique():\n",
    "    minidf = df.loc[(df['ID'] == basename)]\n",
    "    with open(basename+'.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(minidf, pickle_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf28db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\\n!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\\n!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\\n!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\\n!pip install torch-geometric'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cu102.html\n",
    "!pip install torch-geometric'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1854ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.8.0\n",
    "#!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "#!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "#!pip install torch-geometric\n",
    "#!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "#!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "#pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df91b09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi --gpu-reset\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278de72",
   "metadata": {},
   "source": [
    "# 1. Generate Graph Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6905e379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import umap, numba\n",
    "import numpy as np\n",
    "import glob, pandas as pd\n",
    "import pickle\n",
    "import fire\n",
    "import torch_geometric\n",
    "import scipy.sparse as sps\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.data import Data \n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset,DataLoader\n",
    "from torch_cluster import radius_graph\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "# for this program, we're going to create a pseudo whole slide label, you may need to make train, test splits consistent with this label and make sure graphs within patient are assigned to same fold\n",
    "# we will use folds from before just for this example, but see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html\n",
    "# modify as you see fit\n",
    "TUMOR_PERCENT=0.2\n",
    "\n",
    "def remove_ink(ind, ink_reference):\n",
    "    minimum = min(ind)\n",
    "    idx_green = ink_reference['green'] == 1\n",
    "    idx_blue = ink_reference['blue'] == 1\n",
    "    #green = ind[idx_green]\n",
    "    #blue = ind[idx_blue]\n",
    "    for i in range(minimum,minimum+len(idx_blue)):\n",
    "        if idx_blue[i]:\n",
    "            idx_green[i] = True\n",
    "    to_remove = []\n",
    "    for i in range(len(idx_green)):\n",
    "        if idx_green[i]:\n",
    "            to_remove.append(minimum+i)\n",
    "    return np.delete(ind, to_remove)\n",
    "\n",
    "def remove_ink_bool(ink_reference):\n",
    "    ink_reference = embeddings['patch_info']\n",
    "    #ink_reference.reset_index(inplace=True)\n",
    "    minimum = min(ink_reference.index)\n",
    "\n",
    "    ind = ink_reference.index\n",
    "    ig = ink_reference['green'] == 1\n",
    "    ib = ink_reference['blue'] == 1\n",
    "    g = ind[ig]\n",
    "    b = ind[ib]\n",
    "    for i in range(minimum,minimum+len(ib)):\n",
    "        if ib[i]:\n",
    "            ig[i] = True\n",
    "\n",
    "    return ig\n",
    "\n",
    "def get_graph_dataset(embedding_dir='embeddings_prop_ready', \n",
    "                      basename='', \n",
    "                      target_col='tumor', \n",
    "                      target_mapping=dict(), \n",
    "                      k=8,\n",
    "                      radius=0):\n",
    "    #embeddings=torch.load(os.path.join(embedding_dir,f\"{basename}.pkl\"))\n",
    "    embeddings=pd.read_pickle(os.path.join(embedding_dir,f\"{basename}.pkl\"))\n",
    "    #embeddings=pickle.load(os.path.join(embedding_dir,f\"{basename}.pkl\"))\n",
    "    df=embeddings['patch_info']\n",
    "    ink_reference = embeddings['patch_info']\n",
    "    X=pd.DataFrame(embeddings['embeddings'])\n",
    "        #actual embeddings\n",
    "    df['y_true']=df[target_col]\n",
    "        #make a new tumor column \n",
    "    if len(target_mapping): df['y_true']=df['y_true'].map(target_mapping)\n",
    "        #if dict is size 1?\n",
    "    xy=embeddings['patch_info'][['x','y']]\n",
    "    xy=torch.tensor(xy.values).float().cuda()\n",
    "            #xy values to cuda\n",
    "    X=torch.tensor(X.values)\n",
    "            # dict embeddings\n",
    "    y=torch.tensor(df.loc[:,'y_true'].values)\n",
    "        #label\n",
    "    if not radius:\n",
    "        G=knn_graph(xy,k=k)\n",
    "    else:\n",
    "        G=radius_graph(xy, r=radius*np.sqrt(2), batch=None, loop=True)\n",
    "    G=G.detach().cpu()\n",
    "    G=torch_geometric.utils.add_remaining_self_loops(G)[0]\n",
    "    xy=xy.detach().cpu()\n",
    "    datasets=[]\n",
    "    edges=G.detach().cpu().numpy().astype(int)\n",
    "    n_components,components=list(sps.csgraph.connected_components(sps.coo_matrix((np.ones_like(edges[0]),(edges[0],edges[1])))))\n",
    "    components=torch.LongTensor(components)\n",
    "    for i in range(n_components):\n",
    "        G_new=subgraph(components==i,G,relabel_nodes=True)[0]\n",
    "        xy_new=xy[components==i] # actual x, y\n",
    "        X_new=X[components==i] # embeddings\n",
    "        y_new=y[components==i] # tumor label\n",
    "        \n",
    "        y_whole_slide_image_label=y_new.float().mean()>=TUMOR_PERCENT\n",
    "        np.random.seed(42)\n",
    "        idx=np.arange(X_new.shape[0])\n",
    " \n",
    "        idx2=np.arange(X_new.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "        train_idx,val_idx,test_idx=torch.tensor(np.isin(idx2,idx[:int(0.8*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.8*len(idx)):int(0.9*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.9*len(idx)):]))\n",
    "        dataset=Data(x=X_new, edge_index=G_new, edge_attr=None, y=y_new, pos=xy_new, y_wsi=y_whole_slide_image_label)\n",
    "        #####\n",
    "        ink_reference = embeddings['patch_info']\n",
    "       # train_idx_noink = remove_ink(train_idx, ink_reference)\n",
    "       # val_idx_noink = remove_ink(val_idx, ink_reference)\n",
    "       # test_idx_noink = remove_ink(test_idx, ink_reference)\n",
    "\n",
    "       # all_idx_bool_ink = remove_ink_bool(ink_reference)\n",
    "        #####\n",
    "        dataset.train_mask=train_idx\n",
    "        dataset.val_mask=val_idx\n",
    "        dataset.test_mask=test_idx\n",
    "        #####\n",
    "        #dataset.train_mask_noink = train_idx_noink\n",
    "       # dataset.val_mask_noink = val_idx_noink\n",
    "        #dataset.test_mask_noink = test_idx_noink\n",
    "        #dataset.mask = all_idx_bool_ink\n",
    "        #####\n",
    "        \n",
    "        datasets.append(dataset)\n",
    "    components=components.numpy()\n",
    "    \n",
    "    # in this case will use largest connected component, may want to store connected components with size filter (min size connected components after counter) and use component for batching\n",
    "    largest_component=pd.Series(components).value_counts().sort_values(ascending=False).index[0]\n",
    "    dataset=datasets[largest_component]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a078129e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:161",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b0bf622fe362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                       \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                       radius=256*math.sqrt(2)) for ID in tqdm.tqdm(df['ID'].unique())}\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-b0bf622fe362>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m                       \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                       radius=256*math.sqrt(2)) for ID in tqdm.tqdm(df['ID'].unique())}\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-3b6af3c50bcd>\u001b[0m in \u001b[0;36mget_graph_dataset\u001b[0;34m(embedding_dir, basename, target_col, target_mapping, k, radius)\u001b[0m\n\u001b[1;32m     61\u001b[0m                       radius=0):\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m#embeddings=torch.load(os.path.join(embedding_dir,f\"{basename}.pkl\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{basename}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;31m# RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper, mmap]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;31m# expected \"IO[bytes]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:161"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "df=pd.read_pickle(\"DataSplit.pkl\")\n",
    "\n",
    "graph_datasets={ID: get_graph_dataset(embedding_dir='../Scripts/embeddings_prop_ready', \n",
    "                      basename=ID, \n",
    "                      target_col='tumor', \n",
    "                      target_mapping=dict(), \n",
    "                      k=8,\n",
    "                      radius=256*math.sqrt(2)) for ID in tqdm.tqdm(df['ID'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc17de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(dict(graph_dataset=graph_datasets,train_test_splits=dict(zip(df['ID'],df['Set']))),open('graph_data/graph_dataset.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ee3a4",
   "metadata": {},
   "source": [
    "# Label Propogation\n",
    "\n",
    "Create new Propogated Embeddings with Label Propogation Net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71de1bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings=pd.read_pickle(\"../Scripts/embeddings_prop/19.pkl\")\\n\\n\\n\\nink_reference = embeddings[\\'patch_info\\']\\nink_reference.reset_index(inplace=True)\\nminimum = min(ink_reference.index)\\n\\nind = ink_reference.index\\nig = ink_reference[\\'green\\'] == 1\\nib = ink_reference[\\'blue\\'] == 1\\ng = ind[ig]\\nb = ind[ib]\\nfor i in range(minimum,minimum+len(ib)):\\n    if ib[i]:\\n        ig[i] = True\\n        \\nlen(ink_reference)\\n#print(ig)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''embeddings=pd.read_pickle(\"../Scripts/embeddings_prop/19.pkl\")\n",
    "ink_reference = embeddings['patch_info']\n",
    "ink_reference.reset_index(inplace=True)\n",
    "minimum = min(ink_reference.index)\n",
    "ind = ink_reference.index\n",
    "ig = ink_reference['green'] == 1\n",
    "ib = ink_reference['blue'] == 1\n",
    "g = ind[ig]\n",
    "b = ind[ib]\n",
    "for i in range(minimum,minimum+len(ib)):\n",
    "    if ib[i]:\n",
    "        ig[i] = True\n",
    "len(ink_reference)\n",
    "#print(ig)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59993bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings=pd.read_pickle(\"../Scripts/embeddings_prop/19.pkl\")\\nembedding=torch.load(\"../Scripts/cnn_embeddings_1/19.pkl\")\\nembedding[\\'embeddings\\']'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''embeddings=pd.read_pickle(\"../Scripts/embeddings_prop/19.pkl\")\n",
    "embedding=torch.load(\"../Scripts/cnn_embeddings_1/19.pkl\")\n",
    "embedding['embeddings']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5df1f0ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "datasets=pd.read_pickle('graph_data_USE/graph_dataset.pkl')\n",
    "graphy_keys = list(datasets['graph_dataset'].keys())\n",
    "a = pd.read_pickle(\"../Scripts/graph_data_ready_up/graph_dataset.pkl\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "493f2e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nimport tqdm\\n\\ngraphy_keys = list(datasets[\\'graph_dataset\\'].keys())\\ngraphy = list(datasets[\\'graph_dataset\\'].values())\\nfor i in tqdm.tqdm(range(len(graphy_keys))):\\n    embeddings_prop = pd.read_pickle(\"../Scripts/embeddings_prop_ready/\"+str(graphy_keys[i])+ \".pkl\")\\n    print(str(graphy_keys[i]))\\n    #datasets[\\'graph_dataset\\'][str(graphy_keys[i])].x = embeddings_prop.detach().cpu()\\n    #print(\\'shape: \\' +str(len(datasets[\\'graph_dataset\\'][str(graphy_keys[i])].x)))# = embeddings_prop.detach().cpu()'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "graphy_keys = list(datasets['graph_dataset'].keys())\n",
    "graphy = list(datasets['graph_dataset'].values())\n",
    "for i in tqdm.tqdm(range(len(graphy_keys))):\n",
    "    embeddings_prop = pd.read_pickle(\"../Scripts/embeddings_prop_ready/\"+str(graphy_keys[i])+ \".pkl\")\n",
    "    print(str(graphy_keys[i]))\n",
    "    #datasets['graph_dataset'][str(graphy_keys[i])].x = embeddings_prop.detach().cpu()\n",
    "    #print('shape: ' +str(len(datasets['graph_dataset'][str(graphy_keys[i])].x)))# = embeddings_prop.detach().cpu()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9471ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pickle\\nwith open(\"../Scripts/graph_data_ready/graph_dataset.pkl\", \\'wb\\') as pickle_file:\\n    pickle.dump(datasets, pickle_file)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pickle\n",
    "with open(\"../Scripts/graph_data_ready/graph_dataset.pkl\", 'wb') as pickle_file:\n",
    "    pickle.dump(datasets, pickle_file)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a2d5773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fire\n",
    "from visdom import Visdom\n",
    "import pickle\n",
    "import sys, os\n",
    "import umap, numba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import os,glob, pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import copy\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, DeepGraphInfomax, SAGEConv\n",
    "from torch_geometric.nn import DenseGraphConv\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "from torch_geometric.nn import APPNP\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.data import Data \n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset,DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tqdm\n",
    "EPS = 1e-15\n",
    "\n",
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, hidden_topology=[32,64,128,128], p=0.5, p2=0.1, drop_each=True):\n",
    "        super(GCNNet, self).__init__()\n",
    "        self.out_dim=out_dim\n",
    "        self.convs = nn.ModuleList([GATConv(inp_dim, hidden_topology[0])]+[GATConv(hidden_topology[i],hidden_topology[i+1]) for i in range(len(hidden_topology[:-1]))])\n",
    "        self.drop_edge = lambda edge_index: dropout_adj(edge_index,p=p2)[0]\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.fc = nn.Linear(hidden_topology[-1], out_dim)\n",
    "        self.drop_each=drop_each\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.convs:\n",
    "            if self.drop_each and self.training: edge_index=self.drop_edge(edge_index)\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        if self.training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class GCNFeatures(torch.nn.Module):\n",
    "    def __init__(self, gcn, bayes=False):\n",
    "        super(GCNFeatures, self).__init__()\n",
    "        self.gcn=gcn\n",
    "        self.drop_each=bayes\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.gcn.convs:\n",
    "            if self.drop_each: edge_index=self.gcn.drop_edge(edge_index)\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        if self.drop_each:\n",
    "            x = self.gcn.dropout(x)\n",
    "        y = F.softmax(self.gcn.fc(x))\n",
    "        return x,y\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,n_layers=3,K=5,alpha=0.2,self_loops=False):\n",
    "        super().__init__()\n",
    "        assert n_layers>=2\n",
    "        self.propagate=nn.ModuleList([APPNP(K=K,alpha=alpha,add_self_loops=self_loops) for i in range(n_layers)])#AGNNConv()\n",
    "        \n",
    "    def forward(self,x,edge_index,mask):\n",
    "        x_mask=x[mask]\n",
    "        for layer in self.propagate[:-1]:\n",
    "            x=layer(x,edge_index)\n",
    "            x_mask=x[mask]\n",
    "            # relu?\n",
    "        x_mask=x[mask]\n",
    "        return self.propagate[-1](x,edge_index)\n",
    "\n",
    "def labelprop(graph_data='graph_data/graph_dataset.pkl'):\n",
    "\n",
    "    datasets=pd.read_pickle(graph_data)\n",
    "    #d#atasets=torch.load(graph_data)\n",
    "    #with open(graph_data, 'rb') as pickle_file:\n",
    "    #    datasets = pickle.load(pickle_file)\n",
    "    \n",
    "    ############################\n",
    "    \n",
    "    \n",
    "    \n",
    "    graphy_keys = list(datasets['graph_dataset'].keys())\n",
    "    graphy = list(datasets['graph_dataset'].values())\n",
    "\n",
    "\n",
    "    #embeddings_propogated = []\n",
    "    for i in tqdm.tqdm(range(len(graphy_keys))):\n",
    "        annotation = []\n",
    "\n",
    "\n",
    "        test = graphy[i].pos.tolist()\n",
    "        embeddings=torch.load(\"../Scripts/cnn_embeddings_1/\"+str(graphy_keys[i])+ \".pkl\")\n",
    "        emb = embeddings['patch_info']\n",
    "        for x, y in test:\n",
    "\n",
    "            x_info = emb.loc[emb['x'] == x]\n",
    "            xy_info = x_info.loc[x_info['y'] == y]\n",
    "            annot = (int(xy_info['blue']) or int(xy_info['green']))\n",
    "            annotation.append(annot)\n",
    "\n",
    "        print(str(graphy_keys[i]) +str(sum(annotation)))\n",
    "        x= graphy[i].x\n",
    "        x= graphy[i].x\n",
    "        edge_index = graphy[i].edge_index\n",
    "        #mask = graphy[1].mask\n",
    "        mask = annotation\n",
    "        pos = graphy[i].pos\n",
    "\n",
    "\n",
    "        graph_data=Data(x=x,edge_index=edge_index,mask=torch.tensor(mask),pos=torch.tensor(pos))\n",
    "        graph_data.x=graph_data.x.cuda()\n",
    "        graph_data.mask=graph_data.mask.cuda()\n",
    "        graph_data.edge_index=graph_data.edge_index.cuda()\n",
    "\n",
    "        #NET\n",
    "        net=Net(n_layers=30,\n",
    "                  K=15,\n",
    "                 alpha=0.1,\n",
    "                  self_loops=False).cuda()\n",
    "        #PREDS\n",
    "        y_pred=net(graph_data.x,graph_data.edge_index,graph_data.mask)\n",
    "        y_pred.detach().cpu().numpy()\n",
    "        print(y_pred)\n",
    "        print(type(y_pred))\n",
    "\n",
    "\n",
    "        #embeddings_propogated.append(y_pred)\n",
    "        #embeddings_propogated = np.array(embeddings_propogated)\n",
    "        #torch_emb_propogated = torch.from_numpy(embeddings_propogated)\n",
    "        #torch_emb_propogated = torch.from_numpy(y_pred)\n",
    "\n",
    "\n",
    "        datasets['graph_dataset'][str(graphy_keys[i])].x = y_pred\n",
    "        \n",
    "        \n",
    "        with open('../Scripts/embeddings_prop_ready/'+str(graphy_keys[i])+'.pkl', 'wb') as pickle_file:\n",
    "            pickle.dump(y_pred, pickle_file)\n",
    "    ###########################\n",
    "    \n",
    "    with open('../Scripts/graph_data_USE_prop/graph_dataset.pkl', 'wb') as p:\n",
    "            pickle.dump(datasets, p)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bdc583c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/ipykernel_launcher.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5008, 0.2771, 0.0182,  ..., 0.1684, 0.1209, 0.0313],\n",
      "        [0.5480, 0.3034, 0.0200,  ..., 0.1841, 0.1324, 0.0344],\n",
      "        [0.4999, 0.2769, 0.0183,  ..., 0.1677, 0.1209, 0.0314],\n",
      "        ...,\n",
      "        [1.1273, 0.0788, 0.3844,  ..., 0.3024, 0.1251, 0.5972],\n",
      "        [1.1273, 0.0788, 0.3844,  ..., 0.3024, 0.1251, 0.5972],\n",
      "        [0.9204, 0.0643, 0.3139,  ..., 0.2469, 0.1021, 0.4876]],\n",
      "       device='cuda:0')\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:21<35:23, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:48<1:19:48, 48.36s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.80 GiB (GPU 0; 31.75 GiB total capacity; 9.01 GiB already allocated; 1.57 GiB free; 9.83 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0c8d86ec5814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabelprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'graph_data_base/graph_dataset.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-3e838d59ff8e>\u001b[0m in \u001b[0;36mlabelprop\u001b[0;34m(graph_data)\u001b[0m\n\u001b[1;32m    128\u001b[0m                   self_loops=False).cuda()\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m#PREDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-3e838d59ff8e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, mask)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# relu?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch_geometric/nn/conv/appnp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             x = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0;32m--> 111\u001b[0;31m                                size=None)\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# For `GNNExplainer`, we require a separate message and aggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch_geometric/nn/conv/appnp.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.80 GiB (GPU 0; 31.75 GiB total capacity; 9.01 GiB already allocated; 1.57 GiB free; 9.83 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "labelprop(graph_data='graph_data_base/graph_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c51b37ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tqdm\n",
    "EPS = 1e-15\n",
    "\n",
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, hidden_topology=[32,64,128,128], p=0.5, p2=0.1, drop_each=True):\n",
    "        super(GCNNet, self).__init__()\n",
    "        self.out_dim=out_dim\n",
    "        self.convs = nn.ModuleList([GATConv(inp_dim, hidden_topology[0])]+[GATConv(hidden_topology[i],hidden_topology[i+1]) for i in range(len(hidden_topology[:-1]))])\n",
    "        self.drop_edge = lambda edge_index: dropout_adj(edge_index,p=p2)[0]\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.fc = nn.Linear(hidden_topology[-1], out_dim)\n",
    "        self.drop_each=drop_each\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.convs:\n",
    "            if self.drop_each and self.training: edge_index=self.drop_edge(edge_index)\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        if self.training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class GCNFeatures(torch.nn.Module):\n",
    "    def __init__(self, gcn, bayes=False):\n",
    "        super(GCNFeatures, self).__init__()\n",
    "        self.gcn=gcn\n",
    "        self.drop_each=bayes\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.gcn.convs:\n",
    "            if self.drop_each: edge_index=self.gcn.drop_edge(edge_index)\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        if self.drop_each:\n",
    "            x = self.gcn.dropout(x)\n",
    "        y = F.softmax(self.gcn.fc(x))\n",
    "        return x,y\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,n_layers=3,K=5,alpha=0.2,self_loops=False):\n",
    "        super().__init__()\n",
    "        assert n_layers>=2\n",
    "        self.propagate=nn.ModuleList([APPNP(K=K,alpha=alpha,add_self_loops=self_loops) for i in range(n_layers)])#AGNNConv()\n",
    "        \n",
    "    def forward(self,x,edge_index,mask):\n",
    "        x_mask=x[mask]\n",
    "        for layer in self.propagate[:-1]:\n",
    "            x=layer(x,edge_index)\n",
    "            x_mask=x[mask]\n",
    "            # relu?\n",
    "        x_mask=x[mask]\n",
    "        return self.propagate[-1](x,edge_index)\n",
    "\n",
    "def fit_model(graph_data='graph_data/graph_dataset.pkl',\n",
    "                use_weights=False,\n",
    "                n_batches_backward=1,\n",
    "                f1_metric='weighted',\n",
    "                n_epochs=1500,\n",
    "                out_dir='gnn_models',\n",
    "                lr=1e-2,\n",
    "                eta_min=1e-4,\n",
    "                T_max=20,\n",
    "                wd=0,\n",
    "                hidden_topology=[32,64,128,128],\n",
    "                p=0.5,\n",
    "                p2=0.3,\n",
    "                burnin=400,\n",
    "                warmup=100,\n",
    "                gpu_id=0,\n",
    "                batch_size=1,\n",
    "                vis_every=0,\n",
    "                port=5555,\n",
    "                propogation = False\n",
    "                ):\n",
    "    print(gpu_id); torch.cuda.set_device(gpu_id)\n",
    "    if not vis_every: vis=None\n",
    "    else: vis=Visdom(port=port)\n",
    "    datasets=pd.read_pickle(graph_data)\n",
    "    #d#atasets=torch.load(graph_data)\n",
    "    #with open(graph_data, 'rb') as pickle_file:\n",
    "    #    datasets = pickle.load(pickle_file)\n",
    "    \n",
    "    ############################\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    graphy_keys = list(datasets['graph_dataset'].keys())\n",
    "    graphy = list(datasets['graph_dataset'].values())\n",
    "\n",
    "\n",
    "    #embeddings_propogated = []\n",
    "    ###for i in tqdm.tqdm(range(len(graphy_keys))):\n",
    "   #     annotation = []\n",
    "\n",
    "\n",
    "   #     with open(\"../Scripts/embeddings_prop_ready/\"+str(graphy_keys[i])+ \".pkl\", 'rb') as pickle_file:\n",
    "   #         embeddings_prop = pickle.load(pickle_file)\n",
    "        #####embeddings_prop = pd.read_pickle(\"../Scripts/embeddings_prop_ready/\"+str(graphy_keys[i])+ \".pkl\")\n",
    "        #map_location='cpu'\n",
    "        #embeddings_prop.detach().cpu()\n",
    "\n",
    "\n",
    "        #embeddings_propogated.append(y_pred)\n",
    "        #embeddings_propogated = np.array(embeddings_propogated)\n",
    "        #torch_emb_propogated = torch.from_numpy(embeddings_propogated)\n",
    "        #torch_emb_propogated = torch.from_numpy(y_pred)\n",
    "\n",
    "\n",
    "        #datasets['graph_dataset'][str(graphy_keys[i])].x = embeddings_prop.detach().cpu()\n",
    "        \n",
    "        \n",
    "\n",
    "    ###########################\n",
    "\n",
    "    \n",
    "    \n",
    "    ##########################\n",
    "    \n",
    "    train_dataset=[datasets['graph_dataset'][ID] for ID in datasets['train_test_splits'] if datasets['train_test_splits'][ID]=='train']\n",
    "    val_dataset=[datasets['graph_dataset'][ID] for ID in datasets['train_test_splits'] if datasets['train_test_splits'][ID]=='val']\n",
    "    y_train=np.hstack([graph.y.numpy() for graph in train_dataset])\n",
    "    if use_weights: \n",
    "        weights=compute_class_weight('balanced',[0,1],y_train)\n",
    "    else: \n",
    "        weights=None\n",
    "\n",
    "\n",
    "    # load model\n",
    "    model=GCNNet(train_dataset[0].x.shape[1],len(np.unique(y_train)),hidden_topology=hidden_topology,p=p,p2=p2)\n",
    "    model=model.cuda()\n",
    "\n",
    "    # load optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min, last_epoch=-1)\n",
    "    criterion=nn.CrossEntropyLoss(weight=torch.tensor(weights).float() if use_weights else None)\n",
    "    criterion=criterion.cuda()\n",
    "\n",
    "    # initialize val saving\n",
    "    save_mod=False\n",
    "    past_performance=[0]\n",
    "\n",
    "    # dataloaders\n",
    "    dataloaders={}\n",
    "\n",
    "    dataloaders['train']=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    dataloaders['val']=DataLoader(val_dataset,shuffle=True)\n",
    "    dataloaders['warmup']=DataLoader(train_dataset,shuffle=False)\n",
    "    train_loader=dataloaders['warmup']\n",
    "\n",
    "  \n",
    "                        \n",
    "    n_total_batches=0\n",
    "    train_val_f1=[]\n",
    "    for epoch in range(n_epochs):\n",
    "        Y,Y_Pred=[],[]\n",
    "        for i,data in enumerate(train_loader):\n",
    "            n_total_batches+=1\n",
    "            model.train(True)\n",
    "\n",
    "            \n",
    "            #else:\n",
    "            x=data.x.cuda()#a\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.cuda()\n",
    "            y_out=model(x,edge_index)\n",
    "            loss = criterion(y_out, y) / n_batches_backward\n",
    "            loss.backward()\n",
    "            if n_total_batches%n_batches_backward==0 or (i==len(train_loader.dataset)-1):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
    "            Y.append(y.detach().cpu().numpy().flatten())\n",
    "            del x, edge_index, loss, y_out\n",
    "            if epoch <=warmup:\n",
    "                break \n",
    "        if epoch == warmup:\n",
    "            train_loader=dataloaders['train']\n",
    "        if epoch>=burnin:\n",
    "            save_mod=True\n",
    "        train_f1=f1_score(np.hstack(Y),np.hstack(Y_Pred),average=f1_metric)\n",
    "        scheduler.step()\n",
    "        Y,Y_Pred=[],[]\n",
    "        for i,data in enumerate(dataloaders['val']):\n",
    "            model.train(False)\n",
    "            x=data.x.cuda()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.cuda()\n",
    "            y_out=model(x,edge_index)\n",
    "            loss = criterion(y_out, y) \n",
    "            y_prob=F.softmax(y_out).detach().cpu().numpy()\n",
    "            y_pred=y_prob.argmax(1).flatten()\n",
    "            y_true=y.detach().cpu().numpy().flatten()\n",
    "            Y_Pred.append(y_pred)\n",
    "            Y.append(y_true)\n",
    "            if vis_every and epoch%vis_every==0 and not i:\n",
    "                vis.scatter(data.pos.numpy(),opts=dict(markercolor=(y_pred*255).astype(int),webgl=False,markerborderwidth=0,markersize=5),win=\"pred\")\n",
    "                vis.scatter(data.pos.numpy(),opts=dict(markercolor=y_true*255,webgl=False,markerborderwidth=0,markersize=5),win=\"true\")\n",
    "            del x, edge_index, loss, y_out\n",
    "        val_f1=f1_score(np.hstack(Y),np.hstack(Y_Pred),average=f1_metric)\n",
    "        if save_mod and val_f1>=max(past_performance):\n",
    "            best_model_dict=copy.deepcopy(model.state_dict())\n",
    "            past_performance.append(val_f1)\n",
    "        print(epoch,train_f1,val_f1,flush=True)\n",
    "        train_val_f1.append((train_f1,val_f1))\n",
    "\n",
    "    model.load_state_dict(best_model_dict)\n",
    "    torch.save(model.state_dict(),os.path.join(out_dir,f\"model.pth\"))\n",
    "    torch.save(train_val_f1,os.path.join(out_dir,f\"f1.log.pth\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c534583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   10880 MB |   10880 MB |   10880 MB |       0 B  |\\n|       from large pool |   10880 MB |   10880 MB |   10880 MB |       0 B  |\\n|       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   10880 MB |   10880 MB |   10880 MB |       0 B  |\\n|       from large pool |   10880 MB |   10880 MB |   10880 MB |       0 B  |\\n|       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   10880 MB |   10880 MB |   10880 MB |       0 B  |\\n|       from large pool |   10880 MB |   10880 MB |   10880 MB |       0 B  |\\n|       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      85    |      85    |      85    |       0    |\\n|       from large pool |      85    |      85    |      85    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      85    |      85    |      85    |       0    |\\n|       from large pool |      85    |      85    |      85    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      85    |      85    |      85    |       0    |\\n|       from large pool |      85    |      85    |      85    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8230a810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 31.75 GiB total capacity; 11.15 GiB already allocated; 131.00 MiB free; 11.26 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-503a2195e624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mvis_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 )\n",
      "\u001b[0;32m<ipython-input-31-cb6588f8df61>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(graph_data, use_weights, n_batches_backward, f1_metric, n_epochs, out_dir, lr, eta_min, T_max, wd, hidden_topology, p, p2, burnin, warmup, gpu_id, batch_size, vis_every, port, propogation)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvis_every\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVisdom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;31m#d#atasets=torch.load(graph_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#with open(graph_data, 'rb') as pickle_file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;31m# RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper, mmap]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;31m# expected \"IO[bytes]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 31.75 GiB total capacity; 11.15 GiB already allocated; 131.00 MiB free; 11.26 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "fit_model(graph_data='graph_data_USE_prop/graph_dataset.pkl',\n",
    "                use_weights=False,\n",
    "                n_batches_backward=1,\n",
    "                f1_metric='weighted',\n",
    "                n_epochs=500,\n",
    "                out_dir='gnn_models',\n",
    "                lr=1e-2,\n",
    "                eta_min=1e-4,\n",
    "                T_max=20,\n",
    "                wd=0,\n",
    "                hidden_topology=[32,64,128,128],\n",
    "                p=0.5,\n",
    "                p2=0.3,\n",
    "                burnin=400,\n",
    "                warmup=100,\n",
    "                gpu_id=0,\n",
    "                batch_size=20,\n",
    "                vis_every=0,\n",
    "                port=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3205382b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathpretrain.predict import predict\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset,DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29dfb928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GNN TEST\n",
    "datasets1=pd.read_pickle('graph_data/graph_dataset.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596f64c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets=pd.read_pickle('graph_data_ready_up/graph_dataset.pkl')\n",
    "\n",
    "\n",
    "train_dataset=[datasets['graph_dataset'][ID] for ID in datasets['train_test_splits'] if datasets['train_test_splits'][ID]=='train']\n",
    "val_dataset=[datasets['graph_dataset'][ID] for ID in datasets['train_test_splits'] if datasets['train_test_splits'][ID]=='val']\n",
    "y_train=np.hstack([graph.y.numpy() for graph in train_dataset])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92408939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facbec8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295835,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a9be6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=GCNNet(train_dataset[0].x.shape[1],len(np.unique(y_train)),hidden_topology=[32,64,128,128],p=.5,p2=.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c26c85e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#model=model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6bc4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#weights=None\n",
    "#3use_weights = False\n",
    "\n",
    "'''    # load model\n",
    "model=GCNNet(train_dataset[0].x.shape[1],len(np.unique(y_train)),hidden_topology=[32,64,128,128],p=.5,p2=.3)\n",
    "model=model.cuda()\n",
    "\n",
    "    # load optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=wd)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min, last_epoch=-1)\n",
    "criterion=nn.CrossEntropyLoss(weight=torch.tensor(weights).float() if use_weights else None)\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "    # initialize val saving\n",
    "save_mod=False\n",
    "past_performance=[0]\n",
    "\n",
    "    # dataloaders\n",
    "dataloaders={}\n",
    "\n",
    "dataloaders['train']=DataLoader(train_dataset,batch_size=128,shuffle=True)\n",
    "dataloaders['val']=DataLoader(val_dataset,shuffle=True)\n",
    "dataloaders['warmup']=DataLoader(train_dataset,shuffle=False)\n",
    "train_loader=dataloaders['warmup']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb17177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open('graph_data_USE_prop/graph_dataset.pkl', 'rb') as pickle_file:\n",
    "    dataset = pickle.load(pickle_file)\n",
    "\n",
    "#dataset['graph_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f8299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['train_test_splits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09419b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['graph_dataset']['223']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025c4f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['graph_dataset']['11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd368995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test1 = pd.read_pickle('graph_data_USE_prop/graph_dataset.pkl')\n",
    "\n",
    "#test1 = pd.read_pickle('graph_data_base/graph_dataset.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87abd7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_dataset=[test1['graph_dataset'][ID] for ID in test1['train_test_splits'] if test1['train_test_splits'][ID]=='test']\n",
    "y_train=np.hstack([graph.y.numpy() for graph in test_dataset])\n",
    "\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=128, shuffle=True)\n",
    "\n",
    "graph_model = GCNNet(test_dataset[0].x.shape[1],len(np.unique(y_train)),hidden_topology=[32,64,128,128],p=.5,p2=.3)\n",
    "\n",
    "graph_model.load_state_dict(torch.load('gnn_models_ink/model.pth'))\n",
    "\n",
    "\n",
    "graph_model = graph_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fe30b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y,Y_Pred = [],[]\\n\\noptimizer = torch.optim.Adam(graph_model.parameters(),lr=1e-2,weight_decay=0)\\n#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min, last_epoch=-1)\\ncriterion=nn.CrossEntropyLoss()\\ncriterion=criterion.cuda()\\nfor i,data in enumerate(test_dataloader):\\n    \\n            graph_model.train(False)\\n            x=data.x.cuda()\\n            edge_index=data.edge_index.cuda()\\n            y=data.y.cuda()\\n            y_out=graph_model(x,edge_index)\\n            #loss = criterion(y_out, y) \\n            y_prob=F.softmax(y_out).detach().cpu().numpy()\\n            #y_pred=y_prob.argmax(1).flatten()\\n            y_true=y.detach().cpu().numpy().flatten()\\n            Y_Pred.append(y_pred)\\n            Y.append(y_true)'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Y,Y_Pred = [],[]\n",
    "\n",
    "optimizer = torch.optim.Adam(graph_model.parameters(),lr=1e-2,weight_decay=0)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min, last_epoch=-1)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "for i,data in enumerate(test_dataloader):\n",
    "    \n",
    "            graph_model.train(False)\n",
    "            x=data.x.cuda()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.cuda()\n",
    "            y_out=graph_model(x,edge_index)\n",
    "            #loss = criterion(y_out, y) \n",
    "            y_prob=F.softmax(y_out).detach().cpu().numpy()\n",
    "            #y_pred=y_prob.argmax(1).flatten()\n",
    "            y_true=y.detach().cpu().numpy().flatten()\n",
    "            Y_Pred.append(y_pred)\n",
    "            Y.append(y_true)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb0c4d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 378.00 MiB (GPU 0; 31.75 GiB total capacity; 13.06 GiB already allocated; 35.50 MiB free; 13.21 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f0d03d17f95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0my_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m#loss = criterion(y_out, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#y_prob=F.softmax(y_out).detach().cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-69603f8a74c4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_each\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, alpha: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         out = self.propagate(edge_index, x=(x_l, x_r),\n\u001b[0;32m--> 153\u001b[0;31m                              alpha=(alpha_l, alpha_r), size=size)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# For `GNNExplainer`, we require a separate message and aggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, alpha_j, alpha_i, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 378.00 MiB (GPU 0; 31.75 GiB total capacity; 13.06 GiB already allocated; 35.50 MiB free; 13.21 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "Y,Y_Pred = [],[]\n",
    "\n",
    "optimizer = torch.optim.Adam(graph_model.parameters(),lr=1e-2,weight_decay=0)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min, last_epoch=-1)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "for i,data in enumerate(test_dataloader):\n",
    "    \n",
    "            graph_model.train(False)\n",
    "            x=data.x.cuda()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.cuda()\n",
    "            y_out=graph_model(x,edge_index)\n",
    "            #loss = criterion(y_out, y) \n",
    "            #y_prob=F.softmax(y_out).detach().cpu().numpy()\n",
    "            #y_pred=y_prob.argmax(1).flatten()\n",
    "            y_true=y.detach().cpu().numpy()#.flatten()\n",
    "            Y_Pred.append(y_out.detach().cpu().numpy())\n",
    "            Y.append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3874d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Y_Pred = np.array(Y_Pred)\n",
    "Y_Pred = Y_Pred.squeeze()\n",
    "Y_Pred.shape'''\n",
    "\n",
    "y_pred = np.concatenate(Y_Pred, axis=0)  # torch.cat(y_pred,0)\n",
    "y_true = np.concatenate(Y, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a309423d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2f5d4573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y_Pred=softmax(Y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2f41539b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8207783e-06, 2.8207783e-06],\n",
       "       [2.8207783e-06, 2.8207783e-06],\n",
       "       [2.8207783e-06, 2.8207783e-06],\n",
       "       ...,\n",
       "       [2.8207783e-06, 2.8207783e-06],\n",
       "       [2.8207783e-06, 2.8207783e-06],\n",
       "       [2.8207783e-06, 2.8207783e-06]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b48d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d8043b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177256,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "527cadfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177256,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef710c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "#[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00b5ac9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = np.array(Y)\n",
    "Y = Y.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260077fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885593865033327"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true,y_pred[:,1])\n",
    "\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10a8f4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962402028164564"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(Y_flatten,Y_Pred_flatten)\n",
    "\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3a60e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_true,y_pred[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5dfe93c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d2bcf58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/data/init/envs/PathFlowEnv/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='ROC (Area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(-0.01, 0.5)\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "#plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='ROC (Area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (Top Left Zoom In)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d54e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''   trainset = []\n",
    "    valset = []\n",
    "    train_annotation = []\n",
    "    val_annotation = []\n",
    "    \n",
    "    for ID in range(55, len(graphy_keys)):\n",
    "        #56\n",
    "        #44\n",
    "        #getting train pos\n",
    "        traini_mask = datasets['graph_dataset'][ID].train_mask\n",
    "        traini_pos = datasets['graph_dataset'][ID].pos\n",
    "        for i in range(len(mask)):\n",
    "            if(mask[i]==True):\n",
    "                x, y = traini_pos[i]\n",
    "                trainset.append((x, y))\n",
    "        #patchinfo file\n",
    "        global_P_info = datasets['patch_info'][ID]\n",
    "        \n",
    "        #getting val pos\n",
    "        vali_mask = datasets['graph_dataset'][ID].val_mask\n",
    "        vali_pos = datasets['graph_dataset'][ID].pos\n",
    "        for i in range(len(mask)):\n",
    "            if(mask[i]==True):\n",
    "                x_1, y_2 = vali_pos[i]\n",
    "                valset.append((x_1, y_2))\n",
    "    #getting mask for train\n",
    "        for x, y in trainset:\n",
    "\n",
    "            x_info = global_P_info.loc[global_P_info['x'] == x]\n",
    "            xy_info = x_info.loc[x_info['y'] == y]\n",
    "            annot = (int(xy_info['blue']) or int(xy_info['green']))\n",
    "            train_annotation.append(annot)\n",
    "    #getting mask for val\n",
    "        for x, y in valset:\n",
    "\n",
    "            x_info = global_P_info.loc[global_P_info['x'] == x]\n",
    "            xy_info = x_info.loc[x_info['y'] == y]\n",
    "            annot = (int(xy_info['blue']) or int(xy_info['green']))\n",
    "            val_annotation.append(annot)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PathFlowEnv",
   "language": "python",
   "name": "pathflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
